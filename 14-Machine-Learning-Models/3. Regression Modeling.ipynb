{"cells":[{"cell_type":"markdown","source":["# Regression Modeling\n\nLinear regression is the most commonly employed machine learning model since it is highly interpretable and well studied.  This is often the first pass for data scientists modeling continuous variables.  This lesson trains simple and multivariate regression models and interprets the results.\n\n## ![Spark Logo Tiny](https://files.training.databricks.com/images/105/logo_spark_tiny.png) In this lesson you:<br>\n* Motivate the use of linear regression\n* Train a simple regression model\n* Interpret regression models\n* Train a multivariate regression model"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"9322ed4d-1975-4b02-8a14-cf3a178c2710"}}},{"cell_type":"markdown","source":["<iframe  \nsrc=\"//fast.wistia.net/embed/iframe/xfemo2c5fn?videoFoam=true\"\nstyle=\"border:1px solid #1cb1c2;\"\nallowtransparency=\"true\" scrolling=\"no\" class=\"wistia_embed\"\nname=\"wistia_embed\" allowfullscreen mozallowfullscreen webkitallowfullscreen\noallowfullscreen msallowfullscreen width=\"640\" height=\"360\" ></iframe>\n<div>\n<a target=\"_blank\" href=\"https://fast.wistia.net/embed/iframe/xfemo2c5fn?seo=false\">\n  <img alt=\"Opens in new tab\" src=\"https://files.training.databricks.com/static/images/external-link-icon-16x16.png\"/>&nbsp;Watch full-screen.</a>\n</div>"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"a4a7b56e-afc2-4793-b50d-be8c6158422c"}}},{"cell_type":"markdown","source":["-sandbox\n### Lines through Data\n\nTake the example of Boston housing data where we have median value for a number of neighborhoods and variables such as the number of rooms, per capita crime, and economic status of residents.  We might have a number of questions about this data including:<br><br>\n\n1. *Is there a relationship* between our features and median home value?\n2. If there is a relationship, *how strong is that relationship?*\n3. *Which of the features* affect median home value?\n4. *How accurately can we estimate* the effect of each feature on home value?\n5. *How accurately can we predict* on unseen data?\n6. Is the relationship between our features and home value *linear*?\n7. Are there *interaction effects* (e.g. value goes up when an area is not industrial and has more rooms on average) between the features?\n\nGenerally speaking, machine learning models either allow us to infer something about our data or create accurate predictions.  **There is a trade-off between model accuracy and interpretability.**  More complex models generally perform better, which increases their accuracy at the expense of their interpretability.  \n\nLinear regression is a highly interpretable model, allowing us to infer the answers to the questions above.  The predictive power of this model is somewhat limited, however, so if we're concerned about how our model will work on unseen data, we might choose a different model.\n\n<div><img src=\"https://files.training.databricks.com/images/eLearning/ML-Part-1/rm-vs-mdv.png\" style=\"height: 600px; margin: 20px\"/></div>\n\nAt a high level, **linear regression can be thought of as lines put through data.**  The line plotted above uses a linear regression model to create a best guess for the relationship between average number of rooms in a home and home value."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"2e3f1622-0927-44f1-a97f-2d1cfddc4990"}}},{"cell_type":"code","source":["%run \"./Includes/Classroom-Setup\""],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"276dcc47-9f53-4fa8-9ab4-cc310be7803a"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"markdown","source":["-sandbox\n### Simple Linear Regression\n\nSimple linear regression looks to predict a response `Y` using a single input variable `X`.  In the case of the image above, we're predicting median home value, or `Y`, based on the average number of rooms.  More technically, linear regression is estimating the following equation:\n\n&nbsp;&nbsp;&nbsp;&nbsp;`Y ≈ β<sub>0</sub> + β<sub>1</sub>X`\n\nIn this case, `β<sub>0</sub>` and `β<sub>1</sub>` are our **coefficients** where `β<sub>0</sub>` represents the line's intercept with the Y axis and `β<sub>1</sub>` represents the number we multiply by X in order to attain a prediction.  **A simple linear regression model will try to fit our data a closely as possible by estimating these coefficients,** putting a line through the data.\n\n<img alt=\"Side Note\" title=\"Side Note\" style=\"vertical-align: text-bottom; position: relative; height:1.75em; top:0.05em; transform:rotate(15deg)\" src=\"https://files.training.databricks.com/static/images/icon-note.webp\"/> In the case of inferential statistics where we're interested in learning about the relationship between our input features and outputs, it's common to skip the train/test split step, as you'll see in this lesson."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"795236f2-763f-4c0a-9ab3-7c963cc8c37a"}}},{"cell_type":"markdown","source":["Import the Boston dataset."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"c4e33964-91ba-4314-a2b2-5aad03cbd4b8"}}},{"cell_type":"code","source":["bostonDF = (spark.read\n  .option(\"HEADER\", True)\n  .option(\"inferSchema\", True)\n  .csv(\"/mnt/training/bostonhousing/bostonhousing/bostonhousing.csv\")\n  .drop(\"_c0\")\n)\n\ndisplay(bostonDF)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"d2ad9c65-f0f2-4450-934d-72feabf30826"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"markdown","source":["Create a column `features` that has a single input variable `rm` by using `VectorAssembler`"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"4fd32348-0187-451a-b0f5-525cc37aeaf8"}}},{"cell_type":"code","source":["from pyspark.ml.feature import VectorAssembler\n\nfeatureCol = [\"rm\"]\nassembler = VectorAssembler(inputCols=featureCol, outputCol=\"features\")\n\nbostonFeaturizedDF = assembler.transform(bostonDF)\n\ndisplay(bostonFeaturizedDF)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"542a636f-6da7-4bd8-834d-8bd884683138"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"markdown","source":["-sandbox\nFit a linear regression model.\n\n<img alt=\"Side Note\" title=\"Side Note\" style=\"vertical-align: text-bottom; position: relative; height:1.75em; top:0.05em; transform:rotate(15deg)\" src=\"https://files.training.databricks.com/static/images/icon-note.webp\"/> See the <a href=\"http://spark.apache.org/docs/latest/api/python/pyspark.ml.html?highlight=vectorassembler#pyspark.ml.regression.LinearRegression\" target=\"_blank\">LinearRegression</a> documentation for more details."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"c25c01eb-40c9-48b9-a113-8b60577e7494"}}},{"cell_type":"code","source":["from pyspark.ml.regression import LinearRegression\n\nlr = LinearRegression(featuresCol=\"features\", labelCol=\"medv\")\n\nlrModel = lr.fit(bostonFeaturizedDF)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"cf3686a8-b053-4fc4-b963-afb25907b178"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"markdown","source":["### Model Interpretation\n\nInterpreting a linear model entails answering a number of questions:<br><br>\n\n1. What did the model estimate my coefficients to be?\n2. Are my coefficients statistically significant?\n3. How accurate was my model?"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"b241e55a-504d-430b-bd96-6ba0c4d6c2b8"}}},{"cell_type":"markdown","source":["-sandbox\nRecalling that our model looks like `Y ≈ β<sub>0</sub> + β<sub>1</sub>X`, take a look at the model."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"fe465fa6-62b0-46ad-8116-532b80831cee"}}},{"cell_type":"code","source":["print(\"β0 (intercept): {}\".format(lrModel.intercept))\nprint(\"β1 (coefficient for rm): {}\".format(*lrModel.coefficients))"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"33dfe6c3-2e75-4b3b-85d8-d5c1c080c5b2"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"markdown","source":["-sandbox\nFor a 5 bedroom home, our model would predict `-35.7 + (9.1 * 5)` or `$18,900`.  That's not too bad.\n\n<img alt=\"Side Note\" title=\"Side Note\" style=\"vertical-align: text-bottom; position: relative; height:1.75em; top:0.05em; transform:rotate(15deg)\" src=\"https://files.training.databricks.com/static/images/icon-note.webp\"/> The intercept of `-34.7` doesn't make a lot of sense on its own since this would imply that a studio apartment would be worth negative dollars.  Also, we don't have any 1 or 2 bedroom homes in our dataset, so the model will perform poorly on data in this range."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"6ad36d71-4c3a-40b8-8ceb-46d91f3c4206"}}},{"cell_type":"markdown","source":["-sandbox\nIn order to determine whether our coefficients are statistically significant, we need to quantify the likelihood of seeing the association by chance.  One way of doing this is using a p-value.  As a general rule of thumb, a p-value of under .05 indicates statistical significance in that there is less than a 1 in 20 chance of seeing the correlation by mere chance.\n\nDo this using the `summary` attribute of `lrModel`.\n\n<img alt=\"Side Note\" title=\"Side Note\" style=\"vertical-align: text-bottom; position: relative; height:1.75em; top:0.05em; transform:rotate(15deg)\" src=\"https://files.training.databricks.com/static/images/icon-note.webp\"/> The t-statistic can be used instead of p-values.  <a href=\"https://en.wikipedia.org/wiki/P-value\" target=\"_blank\">Read more about p-values here.</a>"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"e29830a2-bfa3-41dc-b7dd-fd64e7737dc4"}}},{"cell_type":"code","source":["summary = lrModel.summary\n\nsummary.pValues"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"eebb3632-8fe5-42b9-b495-cfeba4de0a6a"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"markdown","source":["-sandbox\nThese small p-values indicate that it is highly unlikely to see the correlation of the number of rooms to housing price by chance.  The first value in the list is the p-value for the `rm` feature and the second is that for the intercept.\n\nFinally, we need a way to quantify how accurate our model is.  **R<sup>2</sup> is a measure of the proportion of variance in the dataset explained by the model.**  With R<sup>2</sup>, a higher number is better."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"ab23858c-3566-43d3-81a8-4ba8b0c50fbb"}}},{"cell_type":"code","source":["summary.r2"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"3736d52b-db0f-480a-9a3c-dbe90683d7fd"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"markdown","source":["This indicates that 48% of the variability in home value can be explained using `rm` and the intercept.  While this isn't too high, it's not too bad considering that we're training a model using only one variable."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"33f5f7fd-faec-40c5-a9de-0801d0d32d8e"}}},{"cell_type":"markdown","source":["Finally, take a look at the `summary` attribute of `lrModel` so see other ways of summarizing model performance."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"ea05c418-7bb0-492b-9ca9-d743e4c52748"}}},{"cell_type":"code","source":["[attr for attr in dir(summary) if attr[0] != \"_\"]"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"2a7d9ba3-7938-4f91-b6cc-53454a3d9348"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"markdown","source":["-sandbox\n### Multivariate Regression\n\nWhile simple linear regression involves just a single input feature, multivariate regression takes an arbitrary number of input features.  The same principles apply that we explored in the simple regression example.  The equation for multivariate regression looks like the following where each feature `p` has its own coefficient:\n\n&nbsp;&nbsp;&nbsp;&nbsp;`Y ≈ β<sub>0</sub> + β<sub>1</sub>X<sub>1</sub> + β<sub>2</sub>X<sub>2</sub> + ... + β<sub>p</sub>X<sub>p</sub>`\n\n<img alt=\"Side Note\" title=\"Side Note\" style=\"vertical-align: text-bottom; position: relative; height:1.75em; top:0.05em; transform:rotate(15deg)\" src=\"https://files.training.databricks.com/static/images/icon-note.webp\"/> Our ability to visually explain how our model is performing becomes more limited as our number of features go up since we can only intuitively visualize data in two, possibly three dimensions.  With multivariate regression, we're therefore still putting lines through data, but this is happening in a higher dimensional space."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"81102e1b-f424-44bc-b4c7-68ca4397d18d"}}},{"cell_type":"markdown","source":["Train a multivariate regression model using `rm`, `crim`, and `lstat` as the input features."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"69c0b060-0dcb-4296-993b-b93dc2213aca"}}},{"cell_type":"code","source":["from pyspark.ml.feature import VectorAssembler\n\nfeatureCols = [\"rm\", \"crim\", \"lstat\"]\nassemblerMultivariate = VectorAssembler(inputCols=featureCols, outputCol=\"features\")\n\nbostonFeaturizedMultivariateDF = assemblerMultivariate.transform(bostonDF)\n\ndisplay(bostonFeaturizedMultivariateDF)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"519c27dc-4c82-42c2-83b6-7ac15b9d57c1"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"markdown","source":["Train the model."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"9b988aef-2184-4117-b0ab-0e6d457c127d"}}},{"cell_type":"code","source":["from pyspark.ml.regression import LinearRegression\n\nlrMultivariate = (LinearRegression()\n  .setLabelCol(\"medv\")\n  .setFeaturesCol(\"features\")\n)\n\nlrModelMultivariate = lrMultivariate.fit(bostonFeaturizedMultivariateDF)\n\nsummaryMultivariate = lrModelMultivariate.summary"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"3cdc0689-df73-4f2a-abc0-db60afeee680"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"markdown","source":["-sandbox\nTake a look at the coefficients and R<sup>2</sup> score."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"e2eb0151-97b4-4088-8e37-3602ef985950"}}},{"cell_type":"code","source":["print(\"β0 (intercept): {}\".format(lrModelMultivariate.intercept))\nfor i, (col, coef) in enumerate(zip(featureCols, lrModelMultivariate.coefficients)):\n  print(\"β{} (coefficient for {}): {}\".format(i+1, col, coef))\n  \nprint(\"\\nR2 score: {}\".format(lrModelMultivariate.summary.r2))"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"58d1077d-16b0-4bf7-b514-52d81fd878fa"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"markdown","source":["-sandbox\nOur R<sup>2</sup> score improved from 48% to 64%, indicating that our new model can explain more of the variance in the data."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"7291b69a-6c80-4c9e-8550-e6f524f16de0"}}}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"3. Regression Modeling","dashboards":[],"notebookMetadata":{"pythonIndentUnit":2},"language":"python","widgets":{},"notebookOrigID":2266511824507268}},"nbformat":4,"nbformat_minor":0}
