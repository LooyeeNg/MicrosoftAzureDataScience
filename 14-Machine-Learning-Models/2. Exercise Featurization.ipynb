{"cells":[{"cell_type":"markdown","source":["## Exercise: Finish Featurizing the Dataset\n\nOne common way of handling categorical data is to divide it into bins, a process technically known as discretizing.  For instance, the dataset contains a number of rating scores that can be translated into a value of `1` if they are a highly rated host or `0` if not.\n\nFinish featurizing the dataset by binning the review scores rating into high versus low rated hosts.  Also filter the extreme values and clean the column `price`."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"45725cff-fff6-410d-9c85-0f4a137a5587"}}},{"cell_type":"markdown","source":["Run the following cell to set up our environment."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"afe88cad-d043-402d-96e6-eb91eb25a573"}}},{"cell_type":"code","source":["%run \"./Includes/Classroom-Setup\""],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"5ed0e04a-7b68-4e17-92d2-fb1f2287eb0c"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["**Restore the Dataset from the Featurization module**"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"a7a7abfb-056a-4f52-9da1-833a722fe2ac"}}},{"cell_type":"code","source":["from pyspark.ml import Pipeline\nfrom pyspark.ml.feature import StringIndexer\nfrom pyspark.ml.feature import OneHotEncoder\nfrom pyspark.ml.feature import Imputer\n\nairbnbDF = spark.read.parquet(\"/mnt/training/airbnb/sf-listings/sf-listings-correct-types.parquet\")\n\nindexer = StringIndexer(inputCol=\"room_type\", outputCol=\"room_type_index\")\nencoder = OneHotEncoder(inputCols=[\"room_type_index\"], outputCols=[\"encoded_room_type\"])\nimputeCols = [\n  \"host_total_listings_count\",\n  \"bathrooms\",\n  \"beds\", \n  \"review_scores_rating\",\n  \"review_scores_accuracy\",\n  \"review_scores_cleanliness\",\n  \"review_scores_checkin\",\n  \"review_scores_communication\",\n  \"review_scores_location\",\n  \"review_scores_value\"\n]\nimputer = Imputer(strategy=\"median\", inputCols=imputeCols, outputCols=imputeCols)\n\npipeline = Pipeline(stages=[\n  indexer, \n  encoder, \n  imputer\n])\n\npipelineModel = pipeline.fit(airbnbDF)\ntransformedDF = pipelineModel.transform(airbnbDF)\n\ndisplay(transformedDF)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"17d7083b-d623-45ab-b284-a419fd266a25"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["-sandbox\n### Step 1: Binning `review_scores_rating`\n\nDivide the hosts by whether their `review_scores_rating` is above 97.  Do this using the transformer `Binarizer` with the output column `high_rating`.  This should create the objects `binarizer` and the transformed DataFrame `transformedBinnedDF`.\n\n<img alt=\"Hint\" title=\"Hint\" style=\"vertical-align: text-bottom; position: relative; height:1.75em; top:0.3em\" src=\"https://files.training.databricks.com/static/images/icon-light-bulb.svg\"/>&nbsp;**Hint:** Note that `Binarizer` is a transformer, so it does not have a `.fit()` method<br>\n<img alt=\"Hint\" title=\"Hint\" style=\"vertical-align: text-bottom; position: relative; height:1.75em; top:0.3em\" src=\"https://files.training.databricks.com/static/images/icon-light-bulb.svg\"/>&nbsp;**Hint:** See the <a href=\"http://spark.apache.org/docs/latest/api/python/pyspark.ml.html?highlight=binarizer#pyspark.ml.feature.Binarizer\" target=\"_blank\">Binarizer Docs</a> for more details.</a>"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"92e3ad72-6d7d-4d8c-a590-f5d996bc66b3"}}},{"cell_type":"code","source":["# TODO\nfrom pyspark.ml.feature import Binarizer\n\nbinarizer = Binarizer(threshold=97, inputCol=\"review_scores_rating\", outputCol=\"high_rating\")\ntransformedBinnedDF = binarizer.transform(transformedDF)\n\ndisplay(transformedBinnedDF)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"4027f334-0982-4e40-a40c-11ad80bd47ce"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["# TEST - Run this cell to test your solution\nfrom pyspark.ml.feature import Binarizer\n\ndbTest(\"ML1-P-05-01-01\", True, type(binarizer) == type(Binarizer()))\ndbTest(\"ML1-P-05-01-02\", True, binarizer.getInputCol() == 'review_scores_rating')\ndbTest(\"ML1-P-05-01-03\", True, binarizer.getOutputCol() == 'high_rating')\ndbTest(\"ML1-P-05-01-04\", True, \"high_rating\" in transformedBinnedDF.columns)\n\nprint(\"Tests passed!\")"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"2e2bd3d1-0a14-4c0f-a5d4-9b1d2af3c331"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["-sandbox\n### Step 2: Regular Expressions on Strings\n\nClean the column `price` by creating two new columns:<br><br>\n\n1. `price`: a new column that contains a cleaned version of price.  This can be done using the regular expression replacement of `\"[\\$,]\"` with `\"\"`.  Cast the column as a decimal.\n2. `raw_price`: the collumn `price` in its current form\n\n<img alt=\"Hint\" title=\"Hint\" style=\"vertical-align: text-bottom; position: relative; height:1.75em; top:0.3em\" src=\"https://files.training.databricks.com/static/images/icon-light-bulb.svg\"/>&nbsp;**Hint:** See the <a href=\"http://spark.apache.org/docs/latest/api/python/pyspark.sql.html?highlight=regexp_replace#pyspark.sql.functions.regexp_replace\" target=\"_blank\">`regex_replace` Docs</a> for more details."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"4223dac6-2c5d-4056-b5ee-869aa10ab0ad"}}},{"cell_type":"code","source":["# TODO\nfrom pyspark.sql.functions import col, regexp_replace\n\ntransformedBinnedRegexDF = (transformedBinnedDF\n  .withColumnRenamed(\"price\", \"price_raw\")\n  .withColumn(\"price\", regexp_replace(col(\"price_raw\"), \"[\\$,]\", \"\").cast(\"Decimal(10,2)\"))\n)\n\ndisplay(transformedBinnedRegexDF)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"813d3b8a-587a-469b-a83c-b11691e07d9c"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["# TEST - Run this cell to test your solution\nfrom pyspark.sql.types import DecimalType\n\ndbTest(\"ML1-P-05-02-01\", True, type(transformedBinnedRegexDF.schema[\"price\"].dataType) == type(DecimalType()))\ndbTest(\"ML1-P-05-02-02\", True, \"price_raw\" in transformedBinnedRegexDF.columns)\ndbTest(\"ML1-P-05-02-03\", True, \"price\" in transformedBinnedRegexDF.columns)\n\nprint(\"Tests passed!\")"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"d9ccc9f2-e3c6-41da-a0e3-6882fd4326d5"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["### Step 3: Filter Extremes\n\nThe dataset contains extreme values, including negative prices and minimum stays of over one year.  Filter out all prices of $0 or less and all `minimum_nights` of 365 or higher.  Save the results to `transformedBinnedRegexFilteredDF`."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"ec2d39a4-3464-413c-9420-36a95340b938"}}},{"cell_type":"code","source":["# TODO\nfrom pyspark.sql.functions import col \n\ntransformedBinnedRegexFilteredDF = (transformedBinnedRegexDF\n  .filter(col(\"price\") > 0)\n  .filter(col(\"minimum_nights\") <= 365)\n)\n\ndisplay(transformedBinnedRegexFilteredDF)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"ad76cb59-638a-495c-a798-6c2250d02765"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["# TEST - Run this cell to test your solution\ndbTest(\"ML1-P-05-03-01\", 4789, transformedBinnedRegexFilteredDF.count())\n\nprint(\"Tests passed!\")"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"700e4073-4f14-4914-ac41-a9d49cb62f76"}},"outputs":[],"execution_count":0}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"2. Exercise Featurization","dashboards":[],"notebookMetadata":{"pythonIndentUnit":2},"language":"python","widgets":{},"notebookOrigID":2266511824507299}},"nbformat":4,"nbformat_minor":0}
